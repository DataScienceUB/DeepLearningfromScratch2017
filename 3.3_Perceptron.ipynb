{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.3%20Perceptron.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Y_RrYd1OSOhs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Perceptron with TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "OxFsVC2GSOhs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "8c8794d9-89ab-430d-e79a-14b33da610e6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528878933742,
          "user_tz": -120,
          "elapsed": 4573,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Import MINST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"tmp/data/\", one_hot=True)\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-4666c8b62dd4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7osZkfg1SOhx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "35306440-1b57-44dd-bd70-d8b244f07c88",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528878934278,
          "user_tz": -120,
          "elapsed": 525,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of features\n",
        "n_hidden_2 = 256 # 2nd layer number of features\n",
        "n_input = 784 # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(\"float\", [None, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TLxcD2wSOhz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "31516afe-8694-4d84-c0c6-cf501cbc338e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528878934811,
          "user_tz": -120,
          "elapsed": 484,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "def multilayer_perceptron(x, weights, biases):\n",
        "    # Hidden layer with RELU activation\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    # Output layer with linear activation\n",
        "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RHppzI6oSOh2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0c6b07c8-f564-46e4-9aab-fb9789b43f1d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528878970992,
          "user_tz": -120,
          "elapsed": 577,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}\n",
        "\n",
        "# Construct model\n",
        "pred = multilayer_perceptron(x, weights, biases)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wG-PkTZfSOh4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "5e3a6f8b-79f6-457b-aeb7-b9279673dc55",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528879008940,
          "user_tz": -120,
          "elapsed": 34439,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
        "                                                          y: batch_y})\n",
        "            # Compute average loss\n",
        "            avg_cost += c / total_batch\n",
        "        # Display logs per epoch step\n",
        "        if epoch % display_step == 0:\n",
        "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
        "                \"{:.9f}\".format(avg_cost)\n",
        "    print \"Optimization Finished!\"\n",
        "\n",
        "    # Test model\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
        "    accuracy = sess.run([accuracy], feed_dict={x: mnist.test.images,\n",
        "                                                          y: mnist.test.labels})"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 20.299232648\n",
            "Epoch: 0002 cost= 5.120573610\n",
            "Epoch: 0003 cost= 3.390567693\n",
            "Epoch: 0004 cost= 2.513128784\n",
            "Epoch: 0005 cost= 1.944997817\n",
            "Epoch: 0006 cost= 1.546649608\n",
            "Epoch: 0007 cost= 1.245732133\n",
            "Epoch: 0008 cost= 1.023161706\n",
            "Epoch: 0009 cost= 0.824373712\n",
            "Epoch: 0010 cost= 0.668858461\n",
            "Epoch: 0011 cost= 0.547593954\n",
            "Epoch: 0012 cost= 0.438884579\n",
            "Epoch: 0013 cost= 0.367057379\n",
            "Epoch: 0014 cost= 0.291111244\n",
            "Epoch: 0015 cost= 0.234335157\n",
            "Optimization Finished!\n",
            "Accuracy: 0.9411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EUlptaD0SOh7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}